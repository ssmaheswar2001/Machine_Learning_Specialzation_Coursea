# MACHINE LEARNING SPECIALIZATION
- By Andrew Ng Offered by DeepLearning.AI
<hr/>

## COURSE 1 : [SUPERVISED ML REGRESSION & CLASSIFICATION](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/tree/main/01_Supervised%20ML%20%20Regression%20%26%20Classification)
- Week 01 : [Intro to ML](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/tree/main/01_Supervised%20ML%20%20Regression%20%26%20Classification/W01_Intro%20to%20ML)
    1. [Overview of ML](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/01_Supervised%20ML%20%20Regression%20%26%20Classification/W01_Intro%20to%20ML/01_Overview%20of%20ML.ipynb)
        - Learning Objective
        - Applications of ML
    2. [Supervised vs Unsupervised ML](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/01_Supervised%20ML%20%20Regression%20%26%20Classification/W01_Intro%20to%20ML/02_supervised%20vs%20Unsupervised%20ML.ipynb)
        - What is ML
        - Supervised Learning
        - Supervised Learning Types
        - Unsupervised Learning
    3. [Regression Model](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/01_Supervised%20ML%20%20Regression%20%26%20Classification/W01_Intro%20to%20ML/03_Regression%20Model.ipynb)
        - Linear Regression with one variable
        - Lab : Model Representation
        - Cost Function
        - Cost Function Intuition
        - Visualizing the cost function
        - Lab : Cost Function
    4. [Training the model with GD](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/01_Supervised%20ML%20%20Regression%20%26%20Classification/W01_Intro%20to%20ML/04_Training%20the%20model%20with%20GD.ipynb)
        - Gradient Descent
        - Implementing Gradient Descent
        - Gradient Descent Intuition
        - Learning Rate
        - Gradient Descent for Linear Regression
        - Running Gradient Descent
        - Lab : To automate the process of optimizing w and b using gradient descent
    5. [Linear Regression from Scratch](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/01_Supervised%20ML%20%20Regression%20%26%20Classification/W01_Intro%20to%20ML/05_Linear%20Regression%20From%20Scratch.ipynb)
</br>

- Week 02 : [Regression with Multiple input variables](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/tree/main/01_Supervised%20ML%20%20Regression%20%26%20Classification/W02_Regression%20with%20Multiple%20input%20variables)
    1. [Multiple Linear Regression](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/01_Supervised%20ML%20%20Regression%20%26%20Classification/W02_Regression%20with%20Multiple%20input%20variables/01_Multiple%20Linear%20Regression.ipynb)
        - Multiple Features
        - Vectorization
        - Lab : Python, Numpy and Vectorization
        - Gradient Descent for Multiple Linear Regression
        - Lab : Multiple Linear Regression
        - Gradient Descent with Multiple Variables
    2. [Gradient Descent in Practice](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/01_Supervised%20ML%20%20Regression%20%26%20Classification/W02_Regression%20with%20Multiple%20input%20variables/02_Gradient%20Descent%20in%20Practice.ipynb)
        - Feature Scaling
        - Mean Normalization
        - Z-score Normalization
        - Checking Gradient descent for convergence
        - Choosing the Learning Rate
        - Lab : Feature Scaling and Learning Rate (Multi-Variable)
        - Polynomial Regression 
        - Lab : Feature Engineering & Polynomial Regression
        - Selecting Features
        - Scaling Features
        - Linear Regression using scikit-learn
    3. [Practice Lab Linear Regression](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/01_Supervised%20ML%20%20Regression%20%26%20Classification/W02_Regression%20with%20Multiple%20input%20variables/03_Practice%20Lab%20%20Linear%20Regression.ipynb)   
</br>

- Week 03 : [Classification](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/tree/main/01_Supervised%20ML%20%20Regression%20%26%20Classification/W03_Classification)
    1. [Classification with Logistic Regression](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/01_Supervised%20ML%20%20Regression%20%26%20Classification/W03_Classification/01_Classification%20with%20Logistic%20Regression.ipynb)
        - Classification
        - Lab : Classification
        - Linear Regression Approach
        - Logisitic Regression
        - Lab : Logisitic Regression
        - Sigmoid or Logistic Function
        - Decision Boundary
        - Lab : Logistic Regression, Decision Boundary
    2. [Cost Function for Logistic Regression](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/01_Supervised%20ML%20%20Regression%20%26%20Classification/W03_Classification/02_Cost%20Function%20for%20Logistic%20Regression.ipynb)
        - Logistic Loss Function
        - Lab : Logistic Regression, Logistic Loss
        - Simplified Cost Function for Logistic Regression
        - Lab : Cost Function for Logistic Regression
        - 
    3. [Gradient Descent for Logistic Regression](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/01_Supervised%20ML%20%20Regression%20%26%20Classification/W03_Classification/03_Gradient%20Descent%20for%20Logsitic%20Regression.ipynb)
        - Lab : Gradient Descent for Logistic Regression
        - Logistic Gradient Descent
        - Lab : Logistic Regression Using scikit-Learn
    4. [The Problem of Overfitting](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/01_Supervised%20ML%20%20Regression%20%26%20Classification/W03_Classification/04_The%20Problem%20of%20Overfitting.ipynb)
        - The Problem of Overfitting
        - Regularization to Reduce Overfitting
        - Lab : Overfitting
        - Cost Function with Regularization
        - Regularized Linear Regression
        - Regularizeed Logistic Regression
        - Lab : Regularized Cost and Gradient
#### [Certificate of Completion](https://www.coursera.org/account/accomplishments/verify/ENRWU6E5QDYU)
</br>
</br>

## COURSE 2 : [ADVANCED LEARNING ALGORITHMS](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/tree/main/02_Advanced%20Learning%20Algorithms)
- Week 01 : [Neural Network](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/tree/main/02_Advanced%20Learning%20Algorithms/W01_Neural%20Networks)
    1. [Neural Network Intuition](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/02_Advanced%20Learning%20Algorithms/W01_Neural%20Networks/01_Neural%20Networks%20Intuition.ipynb)
        - Neural Networks
        - Demand Prediction
        - Example : Recognizing images
    2. [Neural Network Model](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/02_Advanced%20Learning%20Algorithms/W01_Neural%20Networks/02_Neural%20Network%20Model.ipynb)
        - Neural Network Layer
        - More Complex Neural Networks
        - Forward Propagation
        - Handwritten digit recognition
        - Lab : Neurons and Layers
    3. [Tensorflow Implementation](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/02_Advanced%20Learning%20Algorithms/W01_Neural%20Networks/03_TensorFlow%20Implementation.ipynb)
        - Inference in Code
        - Build the model using TensorFlow
        - Model for digit Classification
        - Data in Tensorflow
        - Feature vectors
        - Activation vector
        - Building a neural network architecture
        - Lab : Coffee Roasting in Tensorflow
    4. [Neural Network Implmentation in Python](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/02_Advanced%20Learning%20Algorithms/W01_Neural%20Networks/04_Neural%20Network%20implementation%20in%20Python.ipynb)
        -  Forward Propagation in a single layer
        - Lab : Coffee Roasting Numpy
    5. [Speculations on Artificial General Intelligence (AGI)](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/02_Advanced%20Learning%20Algorithms/W01_Neural%20Networks/05_Speculations%20on%20Artificial%20General%20Intelligence%20(AGI).ipynb)
        - Artificial Narrow Intelligence (ANI)
        - Artificial General Intelligence (AGI)
    6. [Vectorization](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/02_Advanced%20Learning%20Algorithms/W01_Neural%20Networks/06_Vectorization.ipynb)
        - How neural networks are implemented efficiently.
        - Matrix Multiplication
</br>

- Week 02 : [Neural Network Training](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/tree/main/02_Advanced%20Learning%20Algorithms/W02_Neural%20Network%20Training)
    1. [Neural Network Training](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/02_Advanced%20Learning%20Algorithms/W02_Neural%20Network%20Training/01_Neural%20Network%20Training.ipynb)
        - Tensorflow implementation
        - Training Details
    2. [Activation Function](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/02_Advanced%20Learning%20Algorithms/W02_Neural%20Network%20Training/02_Activation%20Functions.ipynb)
        - Alternatives to the Sigmoid activation
        - Choosing Activation Functions
        - Why do we need activation functions
        - Lab : ReLu activation
    3. [Multiclass Classification](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/02_Advanced%20Learning%20Algorithms/W02_Neural%20Network%20Training/03_Multiclass%20Classification.ipynb)
        - Multiclass
        - softmax
        - Neural network with softmax output
        - Improved implementation of softmax
        - Classification with multiple outputs.
        - Lab : Softmax Function
        - Lab : Multiclass
    4. [Additional Neural Network Concepts](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/02_Advanced%20Learning%20Algorithms/W02_Neural%20Network%20Training/04_Additional%20Neural%20Network%20Concepts.ipynb)
        - Additional Optimization
        - Additional Layer Types
        - Convolutional layer
        - Convolutional Neural Network
    5. [Back Propagation](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/02_Advanced%20Learning%20Algorithms/W02_Neural%20Network%20Training/05_Back%20Propagation.ipynb)
        - What is a derivative
        - Computation Graph
        - Larger Neural Network
</br>

- Week 03 : [Advice for Applying ML](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/tree/main/02_Advanced%20Learning%20Algorithms/W03_Advice%20for%20Applying%20Machine%20Learning)
    1. [Advice for Applying Machine Learning](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/02_Advanced%20Learning%20Algorithms/W03_Advice%20for%20Applying%20Machine%20Learning/01_Advice%20for%20Applying%20Machine%20Learning.ipynb)
        - Deciding what to try next
        - Evaluating a model
        - Model Selection and Training/Cross validation/test sets
        - Lab : Model Evaluation and Selection
    2. [Bias and Variance](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/02_Advanced%20Learning%20Algorithms/W03_Advice%20for%20Applying%20Machine%20Learning/02_Bias%20and%20Variance.ipynb)
        - Diagnosing bias and variance
        - Regularization and Bias/Variance
        - Establising a baseline level of performance
        - Learning Curves
        - Deciding what to try next revisited
        - Bias/Variance and Neural Networks
        - Lab : Diagnosing Bias and Variance
    3. [Machine Learning Development Process](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/02_Advanced%20Learning%20Algorithms/W03_Advice%20for%20Applying%20Machine%20Learning/03_Machine%20Learning%20Development%20Process.ipynb)
        - Iterative Loop of ML development
        - Error Analysis
        - Adding Data
        - Transfer Learning
        - Full cycle of a machine learning project
    4. [Skewed Database](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/02_Advanced%20Learning%20Algorithms/W03_Advice%20for%20Applying%20Machine%20Learning/04_Skewed%20Datasets.ipynb)
        - Error metrics for skewed datasets
        - Trading off precision and recall
</br>

- Week 04 : [Decision Trees](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/tree/main/02_Advanced%20Learning%20Algorithms/W04_Decision%20Trees)
    1. [Decision Trees](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/02_Advanced%20Learning%20Algorithms/W04_Decision%20Trees/01_Decision%20Trees.ipynb)
        - Decision Trees
        - Learning Process
    2. [Decision Tree Learning](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/02_Advanced%20Learning%20Algorithms/W04_Decision%20Trees/02_Decision%20Tree%20Learning.ipynb)
        - Entropy as a measure of impurity
        - Choosing a split : Information Gain
        - Decision Tree Learning
        - Using one-hot encoding of categorial features
        - Continuous Valued Features
        - Regression Trees
        - Lab : Decision Trees
    3. [Tree Ensembles](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/02_Advanced%20Learning%20Algorithms/W04_Decision%20Trees/03_Tree%20Ensembles.ipynb)
        - Using Multiple Decision Trees
        - Tree ensemble
        - Sampling with replacement
        - Random Forest Algorithm
        - XGBoost
        - When to use decision trees
        - Decision Trees vs Neural Networks
        - Lab : Tree Ensembles - Heart Failure Prediction
#### [Certificate of Completion](https://www.coursera.org/account/accomplishments/verify/M765BBQNHZTB)
</br>
</br>

## COURSE 3 :  [UNSUPERVISED LEARNING, RECOMMENDERS, REINFORCEMENT LEARNING](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/tree/main/03_Unsupervised%20Learning%2C%20Recommenders%2C%20Reinforcement%20Learning)
- Week 01 : [Unsupervised Learning](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/tree/main/03_Unsupervised%20Learning%2C%20Recommenders%2C%20Reinforcement%20Learning/W01_Unsupervsied%20Learning)
    1. Welcome
    2. [Clustering](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/03_Unsupervised%20Learning%2C%20Recommenders%2C%20Reinforcement%20Learning/W01_Unsupervsied%20Learning/02_Clustering.ipynb)
        - What is clustering
        - Applications of Clustering
        - K-means intuition
        - K-means Algorithm
        - Optimization Objective
        - Initializing K-means
        - Choosing the number of clusters
    3. [Anomaly Detection](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/03_Unsupervised%20Learning%2C%20Recommenders%2C%20Reinforcement%20Learning/W01_Unsupervsied%20Learning/03_Anomaly%20Detection.ipynb)
        - Finding unusual events
        - Anomaly Detection
        - Density estimation
        - Gaussian (normal) Detection
        - Anomaly Detection Algorithm
        - Developing and evaluating an anomaly detection system
        - Anomaly Detection vs Supervised Learning
        - Choosing what features to use
    4. [Practice Lab : K-means Clustering](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/03_Unsupervised%20Learning%2C%20Recommenders%2C%20Reinforcement%20Learning/W01_Unsupervsied%20Learning/Practice%20Lab_01.ipynb)
        - Image Compression
    5. [Practice Lab : Anomaly Detection in server computers](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/03_Unsupervised%20Learning%2C%20Recommenders%2C%20Reinforcement%20Learning/W01_Unsupervsied%20Learning/Practice%20Lab_02.ipynb)
</br>

- Week 02 : [Recommender Systems](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/tree/main/03_Unsupervised%20Learning%2C%20Recommenders%2C%20Reinforcement%20Learning/W02_Recommender%20Systems)
    1. [Collaborative Filtering](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/03_Unsupervised%20Learning%2C%20Recommenders%2C%20Reinforcement%20Learning/W02_Recommender%20Systems/01_Collaborative%20Filtering.ipynb)
        - Making Recommendations
        - Using per-item features
        - Collaborative Filtering Algorithm
    2. [Recommender Systems Implementation](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/03_Unsupervised%20Learning%2C%20Recommenders%2C%20Reinforcement%20Learning/W02_Recommender%20Systems/02_Recommender%20Systems%20Implementation%20Detail.ipynb)
        - Mean Normalization
        - Tensorflow implementation of collaborative filtering
        - Finding Related items
    3. [Content Based Filtering](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/03_Unsupervised%20Learning%2C%20Recommenders%2C%20Reinforcement%20Learning/W02_Recommender%20Systems/03_Content%20Based%20Filtering.ipynb)
        - Collaborative Filtering vs Content-base Filtering
        - Deeplearning for content-base filtering
        - Recommending from a large catalogue
        - Tensorflow implementation of content-based filtering
    4. [Principal Component Analysis](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/03_Unsupervised%20Learning%2C%20Recommenders%2C%20Reinforcement%20Learning/W02_Recommender%20Systems/04_Principal%20Component%20Analysis.ipynb)
        - Reducing the number of features
        - PCA algorithm
        - PCA in code 
        - Applications of PCA
        - Lab : PCA and data visulization
    5. [Practice Lab : Collaborative Filtering Recommender Systems](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/03_Unsupervised%20Learning%2C%20Recommenders%2C%20Reinforcement%20Learning/W02_Recommender%20Systems/Practice%20Lab_01.ipynb)
        - Recommender system for movies
    6. [Practice Lab : Deep Learning for Content-based Filtering](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/03_Unsupervised%20Learning%2C%20Recommenders%2C%20Reinforcement%20Learning/W02_Recommender%20Systems/Practice%20Lab_02.ipynb)
        - Recommebder for movies
</br>

- Week 03 : [Reinforcement Learning](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/tree/main/03_Unsupervised%20Learning%2C%20Recommenders%2C%20Reinforcement%20Learning/W03_Reinforcement%20Leaning)
    1. [Reinforcement Learning Introduction](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/03_Unsupervised%20Learning%2C%20Recommenders%2C%20Reinforcement%20Learning/W03_Reinforcement%20Leaning/01_Reinforcement%20Learning%20Introduction.ipynb)
        - What is Reinforcement Learning
        - The return in Reinforcement Learning
        - Making decisions : Polices of reinforcement learning
        - The goal of reinforcement learning
        - Markov Decision Process(MDP)
    2. [State-action value function](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/03_Unsupervised%20Learning%2C%20Recommenders%2C%20Reinforcement%20Learning/W03_Reinforcement%20Leaning/02_State-action%20value%20function.ipynb)
        - State-action value function definition (Q function)
        - Lab : State action value function
            - mars rover example
        - Bellman Equation
        - Random (stochastic) environment
    3. [Continuous state space](https://github.com/ssmaheswar2001/Machine_Learning_Specialzation_Coursea/blob/main/03_Unsupervised%20Learning%2C%20Recommenders%2C%20Reinforcement%20Learning/W03_Reinforcement%20Leaning/03_Continuous%20state%20space.ipynb)
        - Examples of continous state space applications
        - Lunar lander
        - Learning the state-function 
        - Algorithm refinement : Improved neural netwprk architecture
        - Algorithm refinment e-greedy policy
        - Mini-batching and soft-updates
        - The state of reinforcement learning
#### [Certificate of Completion](https://www.coursera.org/account/accomplishments/verify/BELL8NS28H2F)